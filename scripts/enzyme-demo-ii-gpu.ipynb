{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28378399",
   "metadata": {},
   "source": [
    "# Enzyme with GPU \n",
    "\n",
    "Now, we want to take the previous examples and do similar examples on GPU \n",
    "\n",
    "* 1) with CUDA.jl \n",
    "* 2) with KernelAbstractions\n",
    "\n",
    "With CUDA, as far as I know, only writing your own kernels is supported, not cuBLAS. All of my attempts to differentiate e.g. a standard `mul!` don't work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f590d22e",
   "metadata": {},
   "source": [
    "## Enzyme with CUDA.jl\n",
    "\n",
    "We take the last example from the CPU notebook and try to do it on GPU with `CUDA.jl`\n",
    "\n",
    "For this purpose we have to write CUDA kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03984de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/p/tmp/maxgelbr/code/SpeedyExperiments.jl/scripts\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3664f59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `/p/tmp/maxgelbr/code/SpeedyExperiments.jl/scripts`\n",
      "┌ Info: Precompiling SpeedyExperiments [0d28f6d9-48d7-458f-b3e7-42cde83a05c7]\n",
      "└ @ Base loading.jl:1423\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mPackage SpeedyExperiments does not have CUDAKernels in its dependencies:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- If you have SpeedyExperiments checked out for development and have\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  added CUDAKernels as a dependency but haven't updated your primary\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  environment's manifest file, try `Pkg.resolve()`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- Otherwise you may need to report an issue with SpeedyExperiments\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39mLoading CUDAKernels into SpeedyExperiments from project dependency, future warnings for SpeedyExperiments are suppressed.\n"
     ]
    }
   ],
   "source": [
    "import Pkg \n",
    "Pkg.activate(\".\") # make sure this is really the right environment\n",
    "using Enzyme, Test, CUDA, SpeedyExperiments, LinearAlgebra, Adapt\n",
    "CUDA.allowscalar(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ab407",
   "metadata": {},
   "source": [
    "Should be the scripts folder, otherwise change it. If you are using it for the first time, you might need to `]dev ..` the package again. In the `SpeedyExperiments` there are some utilities for GPU usage, like e.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4f411e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mA\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1my\u001b[22m Cu\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mA\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1my\u001b[22m \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1me\u001b[22mSp\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mr\u001b[22mseA\u001b[0m\u001b[1mr\u001b[22mr\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1my\u001b[22m Cu\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1me\u001b[22mM\u001b[0m\u001b[1ma\u001b[22mt\u001b[0m\u001b[1mr\u001b[22mix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "DeviceArray(x)\n",
       "\\end{verbatim}\n",
       "Returns a \\texttt{CuArray} when CUDA is used, otherwise a regular \\texttt{Array}\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "DeviceArray(x)\n",
       "```\n",
       "\n",
       "Returns a `CuArray` when CUDA is used, otherwise a regular `Array`\n"
      ],
      "text/plain": [
       "\u001b[36m  DeviceArray(x)\u001b[39m\n",
       "\n",
       "  Returns a \u001b[36mCuArray\u001b[39m when CUDA is used, otherwise a regular \u001b[36mArray\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?DeviceArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a7f297",
   "metadata": {},
   "source": [
    "We adjust the example from the other notebook, but this time we use the GPU. In order to save some time writing the kernel, we just do an elementwise multiplication. Now let's try to take the derivative, for this we use `autodiff_deferred` instead of the regular `autodiff`. The syntax is the same, but it is adjusted for GPU usage. Note that we have to execute this as a kernel as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23cd4256",
   "metadata": {},
   "outputs": [],
   "source": [
    "function element_mul_kernel!(C, A, B)\n",
    "    i = threadIdx().x\n",
    "    C[i] = A[i]*B[i]\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function grad_mul_kernel!(C, dC, A, dA, B, dB)\n",
    "    Enzyme.autodiff_deferred(element_mul_kernel!, Const, Duplicated(C, dC), Duplicated(A, dA), Duplicated(B, dB))\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "X_1 = DeviceArray(rand(3,3))\n",
    "∂X_1 = zero(X_1) # input, hence zero \n",
    "X_2 = DeviceArray(rand(size(X_1)...))\n",
    "∂X_2 = zero(X_2) # input, hence zero\n",
    "Y = DeviceArray(zeros(size(X_1)...))\n",
    "∂Y = fill!(similar(Y), 1); # output, hence something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37954eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.HostKernel{typeof(grad_mul_kernel!), NTuple{6, CuDeviceMatrix{Float64, 1}}}(grad_mul_kernel!, CuFunction(Ptr{Nothing} @0x000000000310c010, CuModule(Ptr{Nothing} @0x0000000005c623d0, CuContext(0x0000000002b402c0, instance e0ff3f39bda82691))), CUDA.KernelState(Ptr{Nothing} @0x00002b20e5a00000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@cuda threads=length(X_1) grad_mul_kernel!(Y, ∂Y, X_1, ∂X_1, X_2, ∂X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fe4f487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: Y ≈ X_1 .* X_2\n",
       "   Evaluated: [0.518367141735663 0.04514307627053391 0.183222686204985; 0.43110858915650235 0.3155912165251231 0.13808752179289513; 0.2107084030051926 0.06296262389166143 0.1821020051992087] ≈ [0.518367141735663 0.04514307627053391 0.183222686204985; 0.43110858915650235 0.3155912165251231 0.13808752179289513; 0.2107084030051926 0.06296262389166143 0.1821020051992087]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test Y ≈ X_1 .* X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f753a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X_1 ≈ X_2\n",
       "   Evaluated: [0.5825494050811111 0.9523803367679741 0.3894609012488429; 0.5902793013826094 0.5402133039887466 0.8606560948422022; 0.23473898524613512 0.08905694353173121 0.7137234003704515] ≈ [0.5825494050811111 0.9523803367679741 0.3894609012488429; 0.5902793013826094 0.5402133039887466 0.8606560948422022; 0.23473898524613512 0.08905694353173121 0.7137234003704515]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X_1 ≈ X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7dcb90d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X_2 ≈ X_1\n",
       "   Evaluated: [0.8898252014582151 0.04740026072328707 0.4704520675052727; 0.7303467835424993 0.5841974164555143 0.1604444825528284; 0.8976284990933854 0.7069928676502096 0.25514366644653985] ≈ [0.8898252014582151 0.04740026072328707 0.4704520675052727; 0.7303467835424993 0.5841974164555143 0.1604444825528284; 0.8976284990933854 0.7069928676502096 0.25514366644653985]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X_2 ≈ X_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af849af2",
   "metadata": {},
   "source": [
    "Now, we do the same but with a struct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0aa84c",
   "metadata": {},
   "source": [
    " If we use CUDA with custom structs, we have to make sure to use `Adapt` to make our structs avaliable to CUDA, [as explained here](https://cuda.juliagpu.org/stable/tutorials/custom_structs/). The struct also has to have (parametric) types defined, i.e without the `{S,T,U}` we would get an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd99a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_elementwise_mul! (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct PreComputeMul{S,T,U} \n",
    "    Y::S\n",
    "    X_1::T\n",
    "    X_2::U\n",
    "    \n",
    "    function PreComputeMul(X,Y,Z) \n",
    "        @assert length(X) == length(Y) == length(Z)\n",
    "        new{typeof(X),typeof(Y),typeof(Z)}(X,Y,Z)\n",
    "    end \n",
    "end\n",
    "\n",
    "function Adapt.adapt_structure(to, m::PreComputeMul)\n",
    "    Y = Adapt.adapt_structure(to, m.Y)\n",
    "    X_1 = Adapt.adapt_structure(to, m.X_1)\n",
    "    X_2 = Adapt.adapt_structure(to, m.X_2)\n",
    "    PreComputeMul(Y, X_1, X_2)\n",
    "end\n",
    "\n",
    "function element_mul_kernel!(C::PreComputeMul)\n",
    "    i = threadIdx().x\n",
    "    C.Y[i] = C.X_1[i]*C.X_2[i]\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function compute_elementwise_mul!(X::PreComputeMul)\n",
    "    @cuda threads=length(X.Y) element_mul_kernel!(X.Y, X.X_1, X.X_2)\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5e559ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreComputeMul{CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}}([1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [0.0 0.0 0.0; 0.0 0.0 0.0; 0.0 0.0 0.0], [0.0 0.0 0.0; 0.0 0.0 0.0; 0.0 0.0 0.0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = DeviceArray(rand(3,3))\n",
    "∂X_1 = zero(X_1) # input, hence zero \n",
    "X_2 = DeviceArray(rand(size(X_1)...))\n",
    "∂X_2 = zero(X_2) # input, hence zero\n",
    "Y = DeviceArray(zeros(size(X_1)...))\n",
    "∂Y = fill!(similar(Y), 1) # output, hence something\n",
    "\n",
    "X = PreComputeMul(Y, X_1, X_2)\n",
    "∂X = PreComputeMul(∂Y, ∂X_1, ∂X_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1f177",
   "metadata": {},
   "source": [
    "The first way to compute this would also work without the `adapt_structure`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "906505fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.HostKernel{typeof(element_mul_kernel!), Tuple{CuDeviceMatrix{Float64, 1}, CuDeviceMatrix{Float64, 1}, CuDeviceMatrix{Float64, 1}}}(element_mul_kernel!, CuFunction(Ptr{Nothing} @0x0000000011905e60, CuModule(Ptr{Nothing} @0x0000000011905cb0, CuContext(0x0000000002b402c0, instance e0ff3f39bda82691))), CUDA.KernelState(Ptr{Nothing} @0x00002b20e5a00000))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@cuda threads=length(X.Y) element_mul_kernel!(X.Y, X.X_1, X.X_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8fd9ed",
   "metadata": {},
   "source": [
    "But for kernels that actually use the structs, we need it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cefaf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.HostKernel{typeof(element_mul_kernel!), Tuple{PreComputeMul{CuDeviceMatrix{Float64, 1}, CuDeviceMatrix{Float64, 1}, CuDeviceMatrix{Float64, 1}}}}(element_mul_kernel!, CuFunction(Ptr{Nothing} @0x00000000115165b0, CuModule(Ptr{Nothing} @0x0000000007fb2fb0, CuContext(0x0000000002b402c0, instance e0ff3f39bda82691))), CUDA.KernelState(Ptr{Nothing} @0x00002b20e5a00000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@cuda threads=length(X.Y) element_mul_kernel!(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449ceae",
   "metadata": {},
   "source": [
    "Test if the implementation works on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f65038fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: X.Y ≈ X.X_1 .* X.X_2\n",
       "   Evaluated: [0.12712573852891057 0.23446725910034724 0.012028230568762222; 0.16900630393232668 0.6076334912688396 0.26773287122182476; 0.04430743480845625 0.06708683278909719 0.41290929450218006] ≈ [0.12712573852891057 0.23446725910034724 0.012028230568762222; 0.16900630393232668 0.6076334912688396 0.26773287122182476; 0.04430743480845625 0.06708683278909719 0.41290929450218006]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test X.Y ≈ X.X_1 .* X.X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ae94c",
   "metadata": {},
   "source": [
    "Now, we can take the derivative similar to the example without the struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8674e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grad_elementwise_mul_kernel! (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function grad_elementwise_mul_kernel!(A, dA)\n",
    "    Enzyme.autodiff_deferred(element_mul_kernel!, Const, Duplicated(A, dA))\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9c226d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.HostKernel{typeof(grad_elementwise_mul_kernel!), Tuple{PreComputeMul{CuDeviceMatrix{Float64, 1}, CuDeviceMatrix{Float64, 1}, CuDeviceMatrix{Float64, 1}}, PreComputeMul{CuDeviceMatrix{Float64, 1}, CuDeviceMatrix{Float64, 1}, CuDeviceMatrix{Float64, 1}}}}(grad_elementwise_mul_kernel!, CuFunction(Ptr{Nothing} @0x00000000121f7a10, CuModule(Ptr{Nothing} @0x000000001163bac0, CuContext(0x0000000002b402c0, instance e0ff3f39bda82691))), CUDA.KernelState(Ptr{Nothing} @0x00002b20e5a00000))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@cuda threads=length(X.Y) grad_elementwise_mul_kernel!(X, ∂X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e84485ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X_1 ≈ X_2\n",
       "   Evaluated: [0.6757225470713533 0.6629617469870471 0.48239405723117035; 0.3404947156585928 0.708240345050117 0.28412692076096935; 0.1254104958726736 0.07725581087465527 0.7143499334334222] ≈ [0.6757225470713533 0.6629617469870471 0.48239405723117035; 0.3404947156585928 0.708240345050117 0.28412692076096935; 0.1254104958726736 0.07725581087465527 0.7143499334334222]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X_1 ≈ X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1b5899f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X_2 ≈ X_1\n",
       "   Evaluated: [0.1881330422965547 0.35366634676273145 0.02493445014186424; 0.4963551449115172 0.8579481464386808 0.9423002597035267; 0.353299255378438 0.8683726444596267 0.5780210442767031] ≈ [0.1881330422965547 0.35366634676273145 0.02493445014186424; 0.4963551449115172 0.8579481464386808 0.9423002597035267; 0.353299255378438 0.8683726444596267 0.5780210442767031]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X_2 ≈ X_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab48942",
   "metadata": {},
   "source": [
    "## Enzyme with KernelAbstractions.jl \n",
    "\n",
    "Now we do the same but with `KernelAbstractions`. `KernelAbstractions` has the advantage that it works both on CPU and GPU, as we will also see in these examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11565baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "using KernelAbstractions, CUDAKernels, KernelGradients "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712209ff",
   "metadata": {},
   "source": [
    "The syntax for the kernel is almost the same! The `@Const` marks input arguments that are not allowed to be mutated or aliases of other input arguments. It would work without it, but this optimizes the kernel. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21bc438c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KA_element_mul_kernel! (generic function with 5 methods)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function KA_element_mul_kernel!(C, @Const(A), @Const(B))\n",
    "    i, j = @index(Global, NTuple)\n",
    "    C[i,j] = A[i,j] * B[i,j]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633b969",
   "metadata": {},
   "source": [
    "We have to launch it a bit different though. First we define a wrapper around the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "314c84d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "element_mul! (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function element_mul!(a, b, c)\n",
    "    @assert size(a) == size(b) == size(c)\n",
    "  \n",
    "    device = KernelAbstractions.get_device(a) # here we determine if the array is on GPU or CPU\n",
    "    n = device isa GPU ? 256 : 4   # we split how \n",
    "    kernel! = KA_element_mul_kernel!(device, n)\n",
    "    kernel!(a, b, c, ndrange=size(c)) \n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb78409",
   "metadata": {},
   "source": [
    "Then, we launch it. With KernelAbstractions, we have to wait for all computations to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebcf9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = DeviceArray(rand(256,256))\n",
    "X_2 = DeviceArray(rand(size(X_1)...))\n",
    "Y = DeviceArray(zeros(size(X_1)...))\n",
    "\n",
    "ev = element_mul!(Y, X_1, X_2)\n",
    "wait(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f473848e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: Y ≈ X_1 .* X_2\n",
       "   Evaluated: [0.3337103560525394 0.29402818493817334 … 0.06369297065406779 0.3525451580850144; 0.5848881294428624 0.0018374382075833579 … 0.6849936555907357 0.20579007416570225; … ; 0.17890218595999355 0.1726866399127674 … 0.33404988632629096 0.019546283728313463; 0.015449132913712192 0.5957471748490338 … 0.019021526400236976 0.42824716696059906] ≈ [0.3337103560525394 0.29402818493817334 … 0.06369297065406779 0.3525451580850144; 0.5848881294428624 0.0018374382075833579 … 0.6849936555907357 0.20579007416570225; … ; 0.17890218595999355 0.1726866399127674 … 0.33404988632629096 0.019546283728313463; 0.015449132913712192 0.5957471748490338 … 0.019021526400236976 0.42824716696059906]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test Y ≈ X_1 .* X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041cf737",
   "metadata": {},
   "source": [
    "If we'd want to, we could also write this a bit more compact: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0279d804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "device()\n",
       "\\end{verbatim}\n",
       "Return currently used device for KernelAbstractions, either \\texttt{CPU} or \\texttt{CUDADevice}\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "device()\n",
       "```\n",
       "\n",
       "Return currently used device for KernelAbstractions, either `CPU` or `CUDADevice`\n"
      ],
      "text/plain": [
       "\u001b[36m  device()\u001b[39m\n",
       "\n",
       "  Return currently used device for KernelAbstractions, either \u001b[36mCPU\u001b[39m or\n",
       "  \u001b[36mCUDADevice\u001b[39m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?SpeedyExperiments.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbc245ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = DeviceArray(rand(256,256))\n",
    "X_2 = DeviceArray(rand(size(X_1)...))\n",
    "Y = DeviceArray(zeros(size(X_1)...))\n",
    "\n",
    "const device = SpeedyExperiments.device()\n",
    "n = device isa GPU ? 256 : 4   # we split how \n",
    "\n",
    "wait(KA_element_mul_kernel!(device(), n)(Y, X_1, X_2, ndrange=size(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82919f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: Y ≈ X_1 .* X_2\n",
       "   Evaluated: [0.2305129485809078 0.31983404024174666 … 0.8747413994716363 0.7215888755411229; 0.5359386887744276 0.24342308941446172 … 0.0554909996797386 0.018149699166728067; … ; 0.018582370211715143 0.17224335049959472 … 0.697381590135942 0.0322861905012264; 0.03082025174373685 0.5592708971320206 … 0.3280267978897599 0.10224962869549795] ≈ [0.2305129485809078 0.31983404024174666 … 0.8747413994716363 0.7215888755411229; 0.5359386887744276 0.24342308941446172 … 0.0554909996797386 0.018149699166728067; … ; 0.018582370211715143 0.17224335049959472 … 0.697381590135942 0.0322861905012264; 0.03082025174373685 0.5592708971320206 … 0.3280267978897599 0.10224962869549795]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test Y ≈ X_1 .* X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971955a",
   "metadata": {},
   "source": [
    "Now, let's compute the derivatives for this we have to call `autodiff` with the kernel function which in turn is called with the device and the work group size. Then we can call the kernel event created by `autodiff` with the `Duplicated` inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c05ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = DeviceArray(rand(256,256))\n",
    "∂X_1 = zero(X_1) # input, hence zero \n",
    "X_2 = DeviceArray(rand(size(X_1)...))\n",
    "∂X_2 = zero(X_2) # input, hence zero\n",
    "Y = DeviceArray(zeros(size(X_1)...))\n",
    "∂Y = fill!(similar(Y), 1); # output, hence something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "347fc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "∇! = autodiff(KA_element_mul_kernel!(device(), n))\n",
    "wait(∇!(Duplicated(Y, ∂Y), Duplicated(X_1,∂X_1), Duplicated(X_2,∂X_2); ndrange=size(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba9aae94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X_2 ≈ X_1\n",
       "   Evaluated: [0.3001683813417353 0.33651105804500103 … 0.7295775379907252 0.7061833667391895; 0.47716068498995634 0.6277487742370701 … 0.23263185499492556 0.25489388396277823; … ; 0.23988070270197315 0.1709625408576816 … 0.7560901137758668 0.8881407587692896; 0.36252468468521826 0.5508976978441852 … 0.3456348272514411 0.5863218842991311] ≈ [0.3001683813417353 0.33651105804500103 … 0.7295775379907252 0.7061833667391895; 0.47716068498995634 0.6277487742370701 … 0.23263185499492556 0.25489388396277823; … ; 0.23988070270197315 0.1709625408576816 … 0.7560901137758668 0.8881407587692896; 0.36252468468521826 0.5508976978441852 … 0.3456348272514411 0.5863218842991311]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X_2 ≈ X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8db05134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X_1 ≈ X_2\n",
       "   Evaluated: [0.34226680300317047 0.634724995713039 … 0.6093939470517675 0.36332649317030075; 0.8225014923248329 0.5508262962663629 … 0.22134173809291824 0.931128813263804; … ; 0.9546090339230084 0.41419958027403914 … 0.29882720500222815 0.883099791145679; 0.3222634071419628 0.5638991498576006 … 0.5608314859908383 0.6926284720247491] ≈ [0.34226680300317047 0.634724995713039 … 0.6093939470517675 0.36332649317030075; 0.8225014923248329 0.5508262962663629 … 0.22134173809291824 0.931128813263804; … ; 0.9546090339230084 0.41419958027403914 … 0.29882720500222815 0.883099791145679; 0.3222634071419628 0.5638991498576006 … 0.5608314859908383 0.6926284720247491]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X_1 ≈ X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e3b82",
   "metadata": {},
   "source": [
    "Now, let's do this with a struct. First just the regular forward execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30661744",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct KAPreComputeMul{S,T,U} \n",
    "    Y::S\n",
    "    X_1::T\n",
    "    X_2::U\n",
    "    \n",
    "    function KAPreComputeMul(X,Y,Z) \n",
    "        @assert size(X) == size(Y) == size(Z)\n",
    "        new{typeof(X),typeof(Y),typeof(Z)}(X,Y,Z)\n",
    "    end \n",
    "end\n",
    "\n",
    "@kernel function KAstruct_element_mul_kernel!(A)\n",
    "    i, j = @index(Global, NTuple)\n",
    "    A.Y[i,j] = A.X_1[i,j] * A.X_2[i,j]\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "133aef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = DeviceArray(rand(256,256))\n",
    "X_2 = DeviceArray(rand(size(X_1)...))\n",
    "Y = DeviceArray(zeros(size(X_1)...))\n",
    "\n",
    "X = PreComputeMul(Y, X_1, X_2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f55782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(KAstruct_element_mul_kernel!(device(), n)(X, ndrange=size(X.Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7422cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: Y ≈ X_1 .* X_2\n",
       "   Evaluated: [0.7101595915781801 0.008120219688601554 … 0.060897683383751386 0.2754529449739506; 0.14205550322857488 0.6473728339280315 … 0.5340696792862343 0.08308460257713372; … ; 0.5787314607833485 0.30471006301420117 … 0.24251569087196242 0.07301991058396372; 0.44550218641539463 0.37441406755553897 … 0.0013741518998793985 0.7474249479979399] ≈ [0.7101595915781801 0.008120219688601554 … 0.060897683383751386 0.2754529449739506; 0.14205550322857488 0.6473728339280315 … 0.5340696792862343 0.08308460257713372; … ; 0.5787314607833485 0.30471006301420117 … 0.24251569087196242 0.07301991058396372; 0.44550218641539463 0.37441406755553897 … 0.0013741518998793985 0.7474249479979399]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test Y ≈ X_1 .* X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8ad067",
   "metadata": {},
   "source": [
    "Great, now let's also compute some derivatives here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1ce0c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreComputeMul{CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float64, 2, CUDA.Mem.DeviceBuffer}}([1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = DeviceArray(rand(256,256))\n",
    "∂X_1 = zero(X_1) # input, hence zero \n",
    "X_2 = DeviceArray(rand(size(X_1)...))\n",
    "∂X_2 = zero(X_2) # input, hence zero\n",
    "Y = DeviceArray(zeros(size(X_1)...))\n",
    "∂Y = fill!(similar(Y), 1) # output, hence something\n",
    "\n",
    "X = PreComputeMul(Y, X_1, X_2)\n",
    "∂X = PreComputeMul(∂Y, ∂X_1, ∂X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffbca1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "∇! = autodiff(KAstruct_element_mul_kernel!(device(), n))\n",
    "wait(∇!(Duplicated(X, ∂X); ndrange=size(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c83fa4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X_2 ≈ X_1\n",
       "   Evaluated: [0.15391591677219585 0.646132074657528 … 0.5414569874027779 0.9861771809225744; 0.8413944025227638 0.5735657203260538 … 0.2298950840328039 0.8395484685139407; … ; 0.6099415975391191 0.5083973024770879 … 0.21089068454151105 0.26577656580681575; 0.09945135277963224 0.34378484866526393 … 0.19222273798221923 0.7089355837673377] ≈ [0.15391591677219585 0.646132074657528 … 0.5414569874027779 0.9861771809225744; 0.8413944025227638 0.5735657203260538 … 0.2298950840328039 0.8395484685139407; … ; 0.6099415975391191 0.5083973024770879 … 0.21089068454151105 0.26577656580681575; 0.09945135277963224 0.34378484866526393 … 0.19222273798221923 0.7089355837673377]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X_2 ≈ X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78fe7d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X_1 ≈ X_2\n",
       "   Evaluated: [0.6873005577895346 0.4717280706893876 … 0.7711996393728344 0.06964887144950993; 0.1304670292398673 0.1352036301140137 … 0.1295697835184515 0.9733663940943449; … ; 0.8660550077294288 0.6877076928486632 … 0.6646838321316613 0.3120682840128023; 0.7708405757472858 0.601594311518908 … 0.8565597958017475 0.3152767598966769] ≈ [0.6873005577895346 0.4717280706893876 … 0.7711996393728344 0.06964887144950993; 0.1304670292398673 0.1352036301140137 … 0.1295697835184515 0.9733663940943449; … ; 0.8660550077294288 0.6877076928486632 … 0.6646838321316613 0.3120682840128023; 0.7708405757472858 0.601594311518908 … 0.8565597958017475 0.3152767598966769]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X_1 ≈ X_2"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
