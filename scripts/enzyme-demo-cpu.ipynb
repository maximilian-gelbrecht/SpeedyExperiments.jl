{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enzyme.jl Demo for Speedy (CPU)\n",
    "\n",
    "This notebook outlines the basic functionality of Enzyme in examples that use similar structures like Speedy, but we will start a bit easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar Function - Scalar Output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Nextcloud/SpeedyExperiments`\n"
     ]
    }
   ],
   "source": [
    "import Pkg \n",
    "Pkg.activate(\"..\") # make sure this is really the right environment\n",
    "using Enzyme, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: first(autodiff(f1, Active(1.0))) ≈ 2.0\n",
       "   Evaluated: 2.0 ≈ 2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(x) = x*x\n",
    "∂ = autodiff(f1, Active(1.0))\n",
    "@test first(autodiff(f1, Active(1.0))) ≈ 2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first example is a simple scalar function. Here, we use Enzyme's `autodiff` function the frist time. It is Enzyme's central function that computes gradients of the input function. In this example we don't have to do much. We hand over the function `f1` and in the second argument we indicate that the return value of the function is \"active\", i.e. we want to differentiate w.r.t. it. Enzyme expects the user to already allocate the memory for the gradients, as we will also see in the next example. The results are then usually multiplied to this input. This makes sense when we think about the are large chain of operations that the AD usually computes were we already have an input gradient with a certain value that is then further propagated through the chain (i.e. backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutating Function 1\n",
    "\n",
    "Enzyme can handle mutation! This is the main reason why we are interested in it. However, when working with arrays and other non-scalar objects, Enzyme expects the functions to work in-place and return `nothing`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂f∂inp ≈ [3, 0.5, 2.5]\n",
       "   Evaluated: [3.0, 0.5, 2.5] ≈ [3.0, 0.5, 2.5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f2!(y)\n",
    "    y[1] *= 3 \n",
    "    y[2] /= 2\n",
    "    y[3] *= 2.5  \n",
    "    # nothing   # we skip this hear, but also explictly write it \n",
    "end\n",
    "\n",
    "inp = [2., 2, 2]\n",
    "∂f∂inp = fill!(similar(inp), 1) # y is an output of this mutating function that's why we set the shadow to 1 \n",
    "∂2 = autodiff(f2!, Const, Duplicated(inp, ∂f∂inp))\n",
    "@test ∂f∂inp ≈ [3, 0.5, 2.5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we defined `f2!` to update an array in-place. The syntax of `autodiff` is \n",
    "1. Argument: the function \n",
    "1. Argument: the behaviour of the return value, in this case it is `nothing`, its behaviour is constant (`Const`)\n",
    "1. Every further argument: the input arguments of the function, here we have to indicate wheather we want to differentiate w.r.t to them with `Duplicated` or not `Const`\n",
    "\n",
    "`Duplicated` takes in the actual input as the first argument and then a pre-allocated array for the gradient. For input arguments this \"shadow\" should be just zeros, for output arguments the gradient is multiplied with the shadow, so in most cases we will want it to be identity. If an argument is both input and output as it is the case here, it is considered like an output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutating Function 2 \n",
    "\n",
    "Now we add other input arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f3! (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f3!(y, x)\n",
    "    y[1] = 3*x[1] \n",
    "    y[2] = x[2]/2\n",
    "    y[3] = x[3]*2.5  \n",
    "    # nothing\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = [2., 2, 2]\n",
    "∂f∂x1 = zero(x1) # that's an input to the function\n",
    "\n",
    "y1 = zeros(3)\n",
    "∂f∂y1 = fill!(similar(y1), 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∂2 = autodiff(f3!, Const, Duplicated(y1, ∂f∂y1), Duplicated(x1, ∂f∂x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward passes through the function: the input just remains the input and the output is computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: x1 ≈ x1\n",
       "   Evaluated: [2.0, 2.0, 2.0] ≈ [2.0, 2.0, 2.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test x1 ≈ x1 # thats the forward pass, nothing should happen here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: y1 ≈ [3 * x1[1], x1[2] / 2, x1[3] * 2.5]\n",
       "   Evaluated: [6.0, 1.0, 5.0] ≈ [6.0, 1.0, 5.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test y1 ≈ [3*x1[1], x1[2]/2, x1[3]*2.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, $\\frac{\\partial(f3!)}{\\partial (x1)}$, the gradient that we want, is saved in the shadow `∂f∂x1` that we handed over together with `x1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂f∂x1 ≈ [3, 0.5, 2.5]\n",
       "   Evaluated: [3.0, 0.5, 2.5] ≈ [3.0, 0.5, 2.5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂f∂x1 ≈ [3, 0.5, 2.5] # this is the gradient with respect to the input that we (probably) want\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient that the hand over to `autodiff` as a shadow to the output `y1` is set to zero. This is due to technical reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂f∂y1 ≈ zero(y1)\n",
       "   Evaluated: [0.0, 0.0, 0.0] ≈ [0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂f∂y1 ≈ zero(y1) # this is just zero, it is not used in this case "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structs 1 \n",
    "\n",
    "Amazingly, Enzyme can handle `structs` and functions defined on those very well. In this case we will have to use instances of the struct as inputs for `Duplicated`, also for the pre-allocated gradients / shadows. The results for the gradients are saved in the shadowed instance of the struct, here `∂X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "struct PreComputeMul1\n",
    "    X_1\n",
    "    X_2\n",
    "end\n",
    "\n",
    "function compute!(y, a::PreComputeMul1) \n",
    "    mul!(y, a.X_1, a.X_2)\n",
    "end\n",
    "\n",
    "X_1 = rand(5,3)\n",
    "∂X_1 = zero(X_1) # input, hence zero \n",
    "X_2 = rand(3,7)\n",
    "∂X_2 = zero(X_2) # input, hence zero\n",
    "Y = zeros(size(X_1,1), size(X_2,2))\n",
    "∂Y = fill!(similar(Y), 1) # output, hence something\n",
    "∂Y_copy = deepcopy(∂Y)\n",
    "\n",
    "X = PreComputeMul1(X_1, X_2)\n",
    "∂X = PreComputeMul1(∂X_1, ∂X_2)\n",
    "∂2 = autodiff(compute!, Const, Duplicated(Y, ∂Y), Duplicated(X, ∂X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: Y ≈ X_1 * X_2\n",
       "   Evaluated: [0.37451230688640424 0.37013664876879626 … 0.28743103558218003 0.45581274946163713; 1.0760458134025792 0.5713326693875351 … 0.4901343571343515 0.9115786976252107; … ; 1.3265754343580327 0.6486778663911275 … 0.5713374723816322 1.0803217918665573; 0.6384798797590644 0.19644649855263036 … 0.22822479002486376 0.43609764357660485] ≈ [0.37451230688640424 0.37013664876879626 … 0.28743103558218003 0.45581274946163713; 1.0760458134025792 0.5713326693875351 … 0.49013435713435144 0.9115786976252106; … ; 1.3265754343580327 0.6486778663911275 … 0.5713374723816322 1.0803217918665573; 0.6384798797590644 0.19644649855263038 … 0.22822479002486376 0.43609764357660485]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test Y ≈ X_1 * X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient is the derivative multiplied with the input gradient `∂Y`, here $\\frac{\\partial(Y)}{\\partial(X_1)} = X_2$ and $\\frac{\\partial(Y)}{\\partial(X_2)} = X_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X.X_1 ≈ ∂Y_copy * X_2'\n",
       "   Evaluated: [2.9949364057740606 2.7954736223384082 4.082773106787766; 2.9949364057740606 2.7954736223384082 4.082773106787766; … ; 2.9949364057740606 2.7954736223384082 4.082773106787766; 2.9949364057740606 2.7954736223384082 4.082773106787766] ≈ [2.99493640577406 2.7954736223384082 4.082773106787766; 2.99493640577406 2.7954736223384082 4.082773106787766; … ; 2.99493640577406 2.7954736223384082 4.082773106787766; 2.99493640577406 2.7954736223384082 4.082773106787766]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X.X_1 ≈ ∂Y_copy * X_2' # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X.X_2 ≈ X_1' * ∂Y_copy\n",
       "   Evaluated: [1.7933866736456028 1.7933866736456028 … 1.7933866736456028 1.7933866736456028; 2.0492396970934452 2.0492396970934452 … 2.0492396970934452 2.0492396970934452; 2.7195120833556357 2.7195120833556357 … 2.7195120833556357 2.7195120833556357] ≈ [1.7933866736456028 1.7933866736456028 … 1.7933866736456028 1.7933866736456028; 2.0492396970934452 2.0492396970934452 … 2.0492396970934452 2.0492396970934452; 2.7195120833556357 2.7195120833556357 … 2.7195120833556357 2.7195120833556357]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X.X_2 ≈ X_1' * ∂Y_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structs 2 \n",
    "\n",
    "A similar example, but now we save the result in the struct itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct PreComputeMul2\n",
    "    Y\n",
    "    X_1\n",
    "    X_2\n",
    "end\n",
    "\n",
    "function compute!(a::PreComputeMul2) \n",
    "    mul!(a.Y, a.X_1, a.X_2)\n",
    "    # nothing\n",
    "end\n",
    "\n",
    "X_1 = rand(3,3)\n",
    "∂X_1 = zero(X_1) # input, hence zero \n",
    "X_2 = rand(size(X_1)...)\n",
    "∂X_2 = zero(X_2) # input, hence zero\n",
    "Y = zeros(size(X_1)...)\n",
    "∂Y = fill!(similar(Y), 1) # output, hence something\n",
    "∂Y_copy = deepcopy(∂Y)\n",
    "\n",
    "\n",
    "\n",
    "X = PreComputeMul2(Y, X_1, X_2)\n",
    "∂X = PreComputeMul2(∂Y, ∂X_1, ∂X_2)\n",
    "∂2 = autodiff(compute!, Const, Duplicated(X, ∂X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: X.Y ≈ X.X_1 * X.X_2\n",
       "   Evaluated: [0.8624866974075824 0.6596724597891246 0.9929891832729016; 0.5475132598976726 0.2768682368620906 0.3616559734025895; 0.9850263938422328 0.7515854712020125 1.5176797640735056] ≈ [0.8624866974075824 0.6596724597891246 0.9929891832729016; 0.5475132598976726 0.2768682368620906 0.3616559734025895; 0.9850263938422328 0.7515854712020125 1.5176797640735056]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test X.Y ≈ X.X_1 * X.X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the results are saved in the shadow struct `∂X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " 1.1786  1.44219  1.82784\n",
       " 1.1786  1.44219  1.82784\n",
       " 1.1786  1.44219  1.82784"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∂X.X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " 1.1786  1.44219  1.82784\n",
       " 1.1786  1.44219  1.82784\n",
       " 1.1786  1.44219  1.82784"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∂Y_copy * X.X_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: ∂X.X_1 ≈ ∂Y_copy * (X.X_2)'\n",
       "   Evaluated: [1.1786044248967888 1.442189791306392 1.8278402065528419; 1.1786044248967888 1.442189791306392 1.8278402065528419; 1.1786044248967888 1.442189791306392 1.8278402065528419] ≈ [1.1786044248967888 1.442189791306392 1.8278402065528419; 1.1786044248967888 1.442189791306392 1.8278402065528419; 1.1786044248967888 1.442189791306392 1.8278402065528419]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test ∂X.X_1 ≈ ∂Y_copy * X.X_2' # that's the gradient of the output wrt X_1, the first term is the original ∂Y that is mutated by the autodiff call \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@test ∂X.X_2 ≈ X_1' * fill!(similar(Y), 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
