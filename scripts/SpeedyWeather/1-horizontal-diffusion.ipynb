{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Horizontal Diffusion \n",
    "\n",
    "As a fist example, I kind of randomly picked the horizontal diffusion struct / function. \n",
    "\n",
    "But first, we have to load the enviroment, also load a state of SpeedyWeather that we can use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Nextcloud/SpeedyExperiments/scripts`\n"
     ]
    }
   ],
   "source": [
    "import Pkg \n",
    "Pkg.activate(\"..\")\n",
    "\n",
    "using Enzyme, Test, KernelAbstractions, CUDAKernels, CUDA, KernelGradients, SpeedyExperiments, BenchmarkTools, LinearAlgebra, Adapt, Parameters, SpeedyWeather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "progn_vars, diagn_vars, model_setup = initialize_speedy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we want to look into rewriting/adjusting `horizontal_diffusion!` (2D Version) here as an example. First, we will look up how this function is called given an initialized model. Looking up the source code we can see that the function signature is \n",
    "\n",
    "```julia\n",
    " horizontal_diffusion!(  tendency::AbstractMatrix{Complex{NF}}, # tendency of a \n",
    "                            A::AbstractMatrix{Complex{NF}},        # spectral horizontal field\n",
    "                            damp_expl::AbstractMatrix{NF},         # explicit spectral damping\n",
    "                            damp_impl::AbstractMatrix{NF}          # implicit spectral damping\n",
    "                            ) where {NF<:AbstractFloat}\n",
    "```\n",
    "\n",
    "and it is called in the timestepping routine with \n",
    "\n",
    "```julia\n",
    "@unpack vor = progn\n",
    "@unpack vor_tend = diagn.tendencies\n",
    "@unpack damping, damping_impl = M.horizontal_diffusion\n",
    "\n",
    "# set all tendencies to zero\n",
    "fill!(vor_tend,zero(Complex{NF}))\n",
    "\n",
    "  \n",
    "# PROPAGATE THE SPECTRAL STATE INTO THE DIAGNOSTIC VARIABLES\n",
    "gridded!(diagn,progn,M,lf2)\n",
    "\n",
    "# COMPUTE TENDENCIES OF PROGNOSTIC VARIABLES\n",
    "get_tendencies!(diagn,progn,M,lf2)                   \n",
    "\n",
    "vor_lf = view(vor,:,:,1,:)                                      # array view for leapfrog index\n",
    "horizontal_diffusion!(vor_tend,vor_lf,damping,damping_impl)     # diffusion of vorticity\n",
    "```\n",
    "\n",
    "in which `progn` is an instance of the `PrognosticVariables` like the `progn_vars` we intialized, `diagn` is an instance of `DiagnosticVariables` like the `diagn_vars` we initialized and `M` is the `model_setup`  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call it once, so we can later also cross-check our new version later. We have to explicitly add `SpeedyWeather` a few times as those functions are not exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = model_setup \n",
    "diagn = diagn_vars \n",
    "progn = progn_vars \n",
    "lf2 = 2\n",
    "NF = Float32\n",
    "\n",
    "@unpack vor = progn\n",
    "@unpack vor_tend = diagn.tendencies\n",
    "@unpack damping, damping_impl = M.horizontal_diffusion\n",
    "\n",
    "# set all tendencies to zero\n",
    "fill!(vor_tend,zero(Complex{NF}))\n",
    "\n",
    "# PROPAGATE THE SPECTRAL STATE INTO THE DIAGNOSTIC VARIABLES\n",
    "SpeedyWeather.gridded!(diagn,progn,M,lf2)\n",
    "\n",
    "# COMPUTE TENDENCIES OF PROGNOSTIC VARIABLES\n",
    "SpeedyWeather.get_tendencies!(diagn,progn,M,lf2)                   \n",
    "\n",
    "# we want the 2D version: \n",
    "\n",
    "vor_tend = vor_tend[:,:,1]\n",
    "vor_lf = view(vor,:,:,1,1)                                      \n",
    "\n",
    "# we have to convert everything to CuArrays, incase we are on GPU \n",
    "\n",
    "vor_tend = DeviceArray(vor_tend)\n",
    "vor_lf = DeviceArray(vor_lf)\n",
    "damping = DeviceArray(damping)\n",
    "damping_impl = DeviceArray(damping_impl)\n",
    "\n",
    "SpeedyWeather.horizontal_diffusion!(vor_tend,vor_lf,damping,damping_impl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we know how to call the function, let's rewrite it to work on GPU and with Enzyme! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we inspect the old version: \n",
    "\n",
    "\n",
    "```julia \n",
    "function horizontal_diffusion!( tendency::AbstractMatrix{Complex{NF}}, # tendency of a \n",
    "                                A::AbstractMatrix{Complex{NF}},        # spectral horizontal field\n",
    "                                damp_expl::AbstractMatrix{NF},         # explicit spectral damping\n",
    "                                damp_impl::AbstractMatrix{NF}          # implicit spectral damping\n",
    "                                ) where {NF<:AbstractFloat}\n",
    "\n",
    "    lmax,mmax = size(A) .- 1            # degree l, order m but 0-based\n",
    "    @boundscheck size(A) == size(tendency) || throw(BoundsError())\n",
    "    @boundscheck size(A) == size(damp_expl) || throw(BoundsError())\n",
    "    @boundscheck size(A) == size(damp_impl) || throw(BoundsError())\n",
    "    \n",
    "    @inbounds for m in 1:mmax+1         # loop through all spectral modes \n",
    "        for l in m:lmax+1\n",
    "            tendency[l,m] = (tendency[l,m] - damp_expl[l,m]*A[l,m])*damp_impl[l,m]\n",
    "        end\n",
    "    end\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`horizontal_diffusion!` consists of bounds checks and a double for loop. We'll have to write a kernel for the loop and then call this kernel from a wrapper function that also includes the bounds checks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to note is that all matrices that save spherical harmonics like `tendency` here, are only filled in the lower triangle. The loop also only goes over the lower triangle of the matrix, so we have make our GPU operation also only work on the lower triangle, otherwise we waste computational power. The easiest way (that I can think of) is to translate a linear index to the index of the lower triangle. So that $1\\rightarrow(1,1)$, $2\\rightarrow(2,1)$, $3\\rightarrow(2,2)$, $4\\rightarrow(3,1)$ and so on and so furth. We will have to do that all the time, so we will just create a translation array that we will reuse for all other parts of the model as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528×2 Matrix{Int32}:\n",
       "  1   1\n",
       "  2   1\n",
       "  2   2\n",
       "  3   1\n",
       "  3   2\n",
       "  3   3\n",
       "  4   1\n",
       "  4   2\n",
       "  4   3\n",
       "  4   4\n",
       "  5   1\n",
       "  5   2\n",
       "  5   3\n",
       "  ⋮  \n",
       " 32  21\n",
       " 32  22\n",
       " 32  23\n",
       " 32  24\n",
       " 32  25\n",
       " 32  26\n",
       " 32  27\n",
       " 32  28\n",
       " 32  29\n",
       " 32  30\n",
       " 32  31\n",
       " 32  32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    lowertriangle_indices(Lmax::Integer)\n",
    "\n",
    "Returns an array with the indices of the lower triangle of the square matrix with `Lmax` rows/columns\n",
    "\"\"\"\n",
    "function lowertriangle_indices(Lmax::Integer)\n",
    "    N = sum(1:Lmax) # number of elements in the lower triangle\n",
    "    indices = Array{Int32}(undef, N, 2)\n",
    "\n",
    "    count = 1\n",
    "    for i=1:Lmax\n",
    "        for j=1:i\n",
    "            indices[count, 1] = i\n",
    "            indices[count, 2] = j\n",
    "            count += 1\n",
    "        end \n",
    "    end \n",
    "    return DeviceArray(indices)\n",
    "end \n",
    "\n",
    "\"\"\"\n",
    "    lowertriangle_indices(A::AbstractMatrix)\n",
    "\n",
    "Returns an array with the indices of the lower triangle of the square matrix `A`.\n",
    "\"\"\"\n",
    "function lowertriangle_indices(A::AbstractMatrix) \n",
    "    @assert size(A,1) == size(A,2)\n",
    "    lowertriangle_indices(size(A,1))\n",
    "end\n",
    "\n",
    "triangle_indices = lowertriangle_indices(vor_tend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So, now let's write the horizontal diffusion kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kernel function horizontal_diffusion_kernel!(tendency, @Const(A), @Const(damp_expl), @Const(damp_impl), @Const(triangle_index))\n",
    "    I = @index(Global, Linear)\n",
    "    i = triangle_index[I,1]\n",
    "    j = triangle_index[I,2]\n",
    "\n",
    "    tendency[i,j] = (tendency[i,j] - damp_expl[i,j]*A[i,j])*damp_impl[i,j]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the bounds checks from the old version an integrate now the kernel and launch it. We might agree on some other utility functions for the kernel launching later, but here I have a struct called `DeviceSetup` that holds the currently used device and workgroup size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "horizontal_diffusion! (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function horizontal_diffusion!(tendency::AbstractMatrix{Complex{NF}}, # tendency of a \n",
    "    A::AbstractMatrix{Complex{NF}},        # spectral horizontal field\n",
    "    damp_expl::AbstractMatrix{NF},         # explicit spectral damping\n",
    "    damp_impl::AbstractMatrix{NF},          # implicit spectral damping\n",
    "    device_setup::DeviceSetup,              # device the function is executed on\n",
    "    triangle_indices::AbstractArray{Int32,2}   # array with the indices                  \n",
    "    ) where {NF<:AbstractFloat}\n",
    "\n",
    "lmax,mmax = size(A) .- 1            # degree l, order m but 0-based\n",
    "@boundscheck size(A) == size(tendency) || throw(BoundsError())\n",
    "@boundscheck size(A) == size(damp_expl) || throw(BoundsError())\n",
    "@boundscheck size(A) == size(damp_impl) || throw(BoundsError())\n",
    "device = device_setup.device_KA()\n",
    "n = device_setup.n\n",
    "\n",
    "wait(horizontal_diffusion_kernel!(device, n)(tendency, A, damp_expl, damp_impl, triangle_indices, ndrange=size(triangle_indices,1)))\n",
    "\n",
    "end \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to test if it works! We'll compare the old version to the KernelAbstractions version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "const device_setup = DeviceSetup()\n",
    "\n",
    "vor_tend_old = deepcopy(vor_tend)\n",
    "vor_tend_new = deepcopy(vor_tend)\n",
    "\n",
    "SpeedyWeather.horizontal_diffusion!(vor_tend_old, vor_lf, damping, damping_impl)\n",
    "horizontal_diffusion!(vor_tend_new, vor_lf, damping, damping_impl, device_setup, triangle_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: vor_tend_old ≈ vor_tend_new\n",
       "   Evaluated: ComplexF32[0.0f0 + 0.0f0im 0.0f0 + 0.0f0im … 0.0f0 + 0.0f0im 0.0f0 + 0.0f0im; 9.214844f-7 + 0.0f0im 1.1242739f-14 + 9.101589f-15im … 0.0f0 + 0.0f0im 0.0f0 + 0.0f0im; … ; 8.1235026f-5 + 0.0f0im -6.751766f-7 + 1.2070599f-5im … -9.633636f-7 + 9.024164f-6im 0.0f0 + 0.0f0im; 0.87312204f0 + 0.0f0im -2.1297915f-6 - 1.4817448f-5im … -4.4587105f-6 + 3.97241f-5im 1.017148f-5 - 1.3497451f-5im] ≈ ComplexF32[0.0f0 + 0.0f0im 0.0f0 + 0.0f0im … 0.0f0 + 0.0f0im 0.0f0 + 0.0f0im; 9.214844f-7 + 0.0f0im 1.1242739f-14 + 9.101589f-15im … 0.0f0 + 0.0f0im 0.0f0 + 0.0f0im; … ; 8.1235026f-5 + 0.0f0im -6.751766f-7 + 1.2070599f-5im … -9.633636f-7 + 9.024164f-6im 0.0f0 + 0.0f0im; 0.87312204f0 + 0.0f0im -2.1297915f-6 - 1.4817448f-5im … -4.4587105f-6 + 3.97241f-5im 1.017148f-5 - 1.3497451f-5im]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test vor_tend_old ≈ vor_tend_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! \n",
    "\n",
    "Next step, is to bring Enzyme in and show that it is differentiable. For this we'll have to allocate the shadow memory that stores the gradient information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "∂vor_tend = fill!(similar(vor_tend), 1)\n",
    "vor_lf = SpeedyExperiments.cuda_used[] ? CuArray(vor_lf) : Array(vor_lf) # we really need an array and not a subarray\n",
    "∂vor_lf = zero(vor_lf)\n",
    "∂damping = zero(damping)\n",
    "∂damping_impl = zero(damping_impl);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: objects of type SpeedyExperiments.CPUDevice are not callable",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type SpeedyExperiments.CPUDevice are not callable",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[27]:1",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "∇! = autodiff(horizontal_diffusion_kernel!(device_setup.device_KA(), device_setup.n))\n",
    "ev = ∇!(Duplicated(vor_tend, ∂vor_tend), Duplicated(vor_lf, ∂vor_lf), Duplicated(damping, ∂damping), \n",
    "    Duplicated(damping_impl, ∂damping_impl), Const(triangle_indices); ndrange=size(triangle_indices,1))\n",
    "wait(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know of an easy way to prove the derivatives are correct, but as Enzyme has the paradigm to through errors rather than incorrect gradients, let's hope for the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation for SpeedyWeather \n",
    "\n",
    "So far, we used Enzyme and KernelAbstractions very directly. Next, I outline how it could be implemented within Speedy. For this we use the previously used `DeviceSetup` struct and also the `launch_kernel!` function from the `SpeedyExperiments` module. It's almost the same as before, we just launch the kernel slightly differently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const dev = DeviceSetup() # this chooses per default a GPU if one is available and otherwise the CPU \n",
    "\n",
    "function horizontal_diffusion!(tendency::AbstractMatrix{Complex{NF}}, # tendency of a \n",
    "    A::AbstractMatrix{Complex{NF}},        # spectral horizontal field\n",
    "    damp_expl::AbstractMatrix{NF},         # explicit spectral damping\n",
    "    damp_impl::AbstractMatrix{NF},          # implicit spectral damping\n",
    "    device_setup::DeviceSetup,              # device the function is executed on\n",
    "    triangle_indices::AbstractArray{Int32,2}   # array with the indices                  \n",
    "    ) where {NF<:AbstractFloat}\n",
    "\n",
    "    lmax,mmax = size(A) .- 1            # degree l, order m but 0-based\n",
    "    @boundscheck size(A) == size(tendency) || throw(BoundsError())\n",
    "    @boundscheck size(A) == size(damp_expl) || throw(BoundsError())\n",
    "    @boundscheck size(A) == size(damp_impl) || throw(BoundsError())\n",
    "\n",
    "    ev = launch_kernel!(device_setup, horizontal_diffusion_kernel!, size(triangle_indices,1), tendency, A, damp_expl, damp_impl, triangle_indices)\n",
    "    wait(ev)\n",
    "\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vor_tend_old = DeviceArray(dev, deepcopy(vor_tend))\n",
    "vor_tend_new = DeviceArray(dev, deepcopy(vor_tend))\n",
    "\n",
    "SpeedyWeather.horizontal_diffusion!(vor_tend_old, vor_lf, damping, damping_impl)\n",
    "horizontal_diffusion!(vor_tend_new, vor_lf, damping, damping_impl, dev, triangle_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@test vor_tend_old ≈ vor_tend_new"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
